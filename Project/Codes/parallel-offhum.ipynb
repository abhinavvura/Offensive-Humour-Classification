{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-26T20:08:50.599169Z","iopub.status.busy":"2024-05-26T20:08:50.598815Z","iopub.status.idle":"2024-05-26T20:08:54.379532Z","shell.execute_reply":"2024-05-26T20:08:54.378291Z","shell.execute_reply.started":"2024-05-26T20:08:50.599127Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import os\n","\n","# Function to load embeddings from saved files\n","def load_embeddings(directory):\n","    # Extract numeric ranges and sort filenames accordingly\n","    def extract_range(filename):\n","        start, end = map(int, filename.rstrip('.npy').split('_')[-2:])\n","        return start, end\n","    \n","    # Get sorted filenames\n","    sentence_embeddings_files = sorted([f for f in os.listdir(directory) if f.startswith('sentence_embeddings_') and f.endswith('.npy')],\n","                                       key=extract_range)\n","    text_embeddings_files = sorted([f for f in os.listdir(directory) if f.startswith('text_embeddings_') and f.endswith('.npy')],\n","                                   key=extract_range)\n","    \n","    sentence_embeddings_list = []\n","    text_embeddings_list = []\n","    \n","    for sentence_file, text_file in zip(sentence_embeddings_files, text_embeddings_files):\n","        print(f\"Loading sentence embeddings from file: {sentence_file}\")\n","        sentence_embeddings = np.load(os.path.join(directory, sentence_file))\n","        \n","        print(f\"Loading text embeddings from file: {text_file}\")\n","        text_embeddings = np.load(os.path.join(directory, text_file))\n","        \n","        sentence_embeddings_list.append(sentence_embeddings)\n","        text_embeddings_list.append(text_embeddings)\n","    \n","    all_sentence_embeddings = np.concatenate(sentence_embeddings_list, axis=0)\n","    all_text_embeddings = np.concatenate(text_embeddings_list, axis=0)\n","    \n","    return all_sentence_embeddings, all_text_embeddings\n","\n","# Load embeddings for training\n","all_sentence_embeddings, all_text_embeddings = load_embeddings('/kaggle/input/embeddings/embeddings')\n","print(\"All Sentence Embeddings Shape:\", all_sentence_embeddings.shape)\n","print(\"All Text Embeddings Shape:\", all_text_embeddings.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T20:10:04.351566Z","iopub.status.busy":"2024-05-26T20:10:04.350614Z","iopub.status.idle":"2024-05-26T20:10:05.545621Z","shell.execute_reply":"2024-05-26T20:10:05.544637Z","shell.execute_reply.started":"2024-05-26T20:10:04.351529Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from transformers import BertTokenizer, TFBertModel\n","import tensorflow as tf\n","import os\n","\n","# Load labels from CSV file\n","labels_df = pd.read_csv('/kaggle/input/offensive-humor-detection/Offensive_Humor_detection.csv')\n","labels = labels_df['joke_type'].values\n","print(\"Labels Shape:\", labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T20:10:07.751905Z","iopub.status.busy":"2024-05-26T20:10:07.751026Z","iopub.status.idle":"2024-05-26T20:10:07.757415Z","shell.execute_reply":"2024-05-26T20:10:07.756307Z","shell.execute_reply.started":"2024-05-26T20:10:07.751869Z"},"trusted":true},"outputs":[],"source":["# Define the neural network architecture\n","max_sentences = all_sentence_embeddings.shape[1]  # Number of sentences per sample\n","embedding_dim = all_sentence_embeddings.shape[2]  # Embedding dimension\n","\n","print(max_sentences)\n","print(embedding_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T20:10:08.408816Z","iopub.status.busy":"2024-05-26T20:10:08.407929Z","iopub.status.idle":"2024-05-26T20:10:08.643598Z","shell.execute_reply":"2024-05-26T20:10:08.642533Z","shell.execute_reply.started":"2024-05-26T20:10:08.408784Z"},"trusted":true},"outputs":[],"source":["# Convert labels to numpy array\n","labels = np.array(labels)\n","all_sentence_embeddings = np.array(all_sentence_embeddings)\n","all_text_embeddings = np.array(all_text_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T20:32:11.559238Z","iopub.status.busy":"2024-05-26T20:32:11.558529Z","iopub.status.idle":"2024-05-26T20:32:11.882430Z","shell.execute_reply":"2024-05-26T20:32:11.881481Z","shell.execute_reply.started":"2024-05-26T20:32:11.559202Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n","from sklearn.model_selection import train_test_split\n","\n","# Define the necessary parameters\n","num_sentences = 6  # Replace with your actual number of sentences per sample\n","embedding_dim = 768  # Dimension of the BERT embeddings\n","num_classes = 4  # Number of classes for classification\n","\n","# Input shape for sentence embeddings\n","input_sentences = Input(shape=(num_sentences, embedding_dim))\n","\n","# Define parallel lines for sentence embeddings\n","sentence_outputs = []\n","for _ in range(num_sentences):\n","    x = Dense(128, activation='relu')(input_sentences[:, _, :])\n","    x = Dropout(0.2)(x)\n","    x = Dense(64, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    sentence_output = Dense(20, activation='relu')(x)\n","    sentence_outputs.append(sentence_output)\n","\n","# Input shape for text embeddings\n","input_text = Input(shape=(embedding_dim,))\n","\n","# Define parallel lines for text embeddings\n","text_outputs = []\n","for _ in range(3):\n","    x = Dense(128, activation='relu')(input_text)\n","    x = Dropout(0.2)(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    text_output = Dense(60, activation='relu')(x)\n","    text_outputs.append(text_output)\n","\n","# Concatenate the outputs of sentence and text branches\n","concatenated = Concatenate()(sentence_outputs + text_outputs)\n","\n","# Define a fully connected layer\n","x = Dense(256, activation='relu')(concatenated)\n","x = Dropout(0.2)(x)\n","\n","# Define the sequential layers\n","sequential_layers = Sequential([\n","    Dense(128, activation='relu'),\n","    Dropout(0.2),\n","    Dense(64, activation='relu'),\n","    Dropout(0.2),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# Connect the fully connected layer with the sequential layers\n","output = sequential_layers(x)\n","\n","# Build the model\n","model = Model(inputs=[input_sentences, input_text], outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T20:32:13.298980Z","iopub.status.busy":"2024-05-26T20:32:13.298606Z","iopub.status.idle":"2024-05-26T20:33:33.836315Z","shell.execute_reply":"2024-05-26T20:33:33.834834Z","shell.execute_reply.started":"2024-05-26T20:32:13.298949Z"},"trusted":true},"outputs":[],"source":["# Example data\n","num_samples = 21860  # Replace with your actual number of samples\n","num_sentences = 6  # Replace with your actual number of sentences per sample\n","embedding_dim = 768  # Typically the output dimension of BERT embeddings\n","\n","# Replace these with your actual data\n","X_sentence_embeddings = all_sentence_embeddings  # This should be of shape (num_samples, num_sentences, embedding_dim)\n","X_text_embeddings = all_text_embeddings  # This should be of shape (num_samples, embedding_dim)\n","y_labels = labels  # This should be of shape (num_samples,)\n","\n","# Ensure your data is the correct shape\n","assert X_sentence_embeddings.shape == (num_samples, num_sentences, embedding_dim)\n","assert X_text_embeddings.shape == (num_samples, embedding_dim)\n","assert y_labels.shape[0] == num_samples\n","\n","# Split data into training and validation sets\n","X_train_sentences, X_val_sentences, X_train_text, X_val_text, y_train, y_val = train_test_split(\n","    X_sentence_embeddings, X_text_embeddings, y_labels, test_size=0.2, random_state=42\n",")\n","\n","# Train the model\n","history = model.fit(\n","    [X_train_sentences, X_train_text],\n","    y_train,\n","    validation_data=([X_val_sentences, X_val_text], y_val),\n","    epochs=10,  # Set the number of epochs\n","    batch_size=32,  # Set the batch size\n","    verbose=1  # Print progress during training\n",")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5061774,"sourceId":8485477,"sourceType":"datasetVersion"},{"datasetId":5078472,"sourceId":8507903,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
